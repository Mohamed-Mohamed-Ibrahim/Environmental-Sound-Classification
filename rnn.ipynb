{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12092109,"sourceType":"datasetVersion","datasetId":7612161}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pickle\n\nimport time\nimport math\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\n\n# from name_dataset import NameDataset\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:53:24.933117Z","iopub.execute_input":"2025-06-08T10:53:24.933390Z","iopub.status.idle":"2025-06-08T10:53:26.989713Z","shell.execute_reply.started":"2025-06-08T10:53:24.933370Z","shell.execute_reply":"2025-06-08T10:53:26.988859Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/urbansound8k-feature-extraction/train_data.pkl', 'rb') as f:\n    X_train, Y_train = pickle.load(f)\n\nwith open('/kaggle/input/urbansound8k-feature-extraction/val_data.pkl', 'rb') as f:\n    X_val, Y_val = pickle.load(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:17:16.282505Z","iopub.execute_input":"2025-06-08T12:17:16.283116Z","iopub.status.idle":"2025-06-08T12:17:20.431805Z","shell.execute_reply.started":"2025-06-08T12:17:16.283025Z","shell.execute_reply":"2025-06-08T12:17:20.430810Z"}},"outputs":[],"execution_count":155},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef stack_samples(X, Y):\n    \"\"\"\n    X: list or array of shape (N, R, C)\n    Y: list of N labels\n    Returns: DataFrame of shape (N×R, C + 1)\n    \"\"\"\n    X_np = np.array(X, dtype=np.float32)  # Shape: (N, R, C)\n    Y_repeated = np.repeat(Y, X_np.shape[1])  # Repeat each label R times\n\n    X_stacked = X_np.reshape(-1, X_np.shape[2])  # (N×R, C)\n\n    df = pd.DataFrame(X_stacked)\n    df['Label'] = Y_repeated\n\n    return df\n\ntrain_df = stack_samples(X_train, Y_train)\nval_df = stack_samples(X_val, Y_val)\nprint(train_df.shape)\nprint(val_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:18:27.382603Z","iopub.execute_input":"2025-06-08T12:18:27.383003Z","iopub.status.idle":"2025-06-08T12:18:29.110831Z","shell.execute_reply.started":"2025-06-08T12:18:27.382976Z","shell.execute_reply":"2025-06-08T12:18:29.109616Z"}},"outputs":[{"name":"stdout","text":"(1173960, 181)\n(355104, 181)\n","output_type":"stream"}],"execution_count":159},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:17:37.075922Z","iopub.execute_input":"2025-06-08T12:17:37.076883Z","iopub.status.idle":"2025-06-08T12:17:37.122684Z","shell.execute_reply.started":"2025-06-08T12:17:37.076848Z","shell.execute_reply":"2025-06-08T12:17:37.121730Z"}},"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"          0         1          2          3          4         5          6  \\\n0  0.027114  0.069684   0.084108   0.086272   0.086115  0.068998   0.075101   \n1  0.430208  5.758408  51.152721  60.381077  21.515299  4.466881  13.074950   \n2  0.356129  2.768868  10.043193   5.306677   2.211567  2.200262   5.633092   \n3  0.119155  0.518129   1.104150   0.707675   0.361656  0.435153   0.531613   \n4  0.200908  0.502827   0.919906   0.679136   0.617777  0.499163   0.740346   \n\n           7          8          9  ...        171       172  173  174  175  \\\n0   0.081550   0.082987   0.075951  ...   0.078393  0.053319  0.0  0.0  0.0   \n1  55.018288  43.365993  16.410397  ...  25.460247  5.669981  0.0  0.0  0.0   \n2  11.511503   4.667964   2.912486  ...   5.367310  2.295357  0.0  0.0  0.0   \n3   1.172129   1.274063   1.586210  ...   1.393059  0.565431  0.0  0.0  0.0   \n4   0.879904   0.768322   0.788436  ...   1.237146  0.505317  0.0  0.0  0.0   \n\n   176  177  178  179       Label  \n0  0.0  0.0  0.0  0.0  jackhammer  \n1  0.0  0.0  0.0  0.0  jackhammer  \n2  0.0  0.0  0.0  0.0  jackhammer  \n3  0.0  0.0  0.0  0.0  jackhammer  \n4  0.0  0.0  0.0  0.0  jackhammer  \n\n[5 rows x 181 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>171</th>\n      <th>172</th>\n      <th>173</th>\n      <th>174</th>\n      <th>175</th>\n      <th>176</th>\n      <th>177</th>\n      <th>178</th>\n      <th>179</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.027114</td>\n      <td>0.069684</td>\n      <td>0.084108</td>\n      <td>0.086272</td>\n      <td>0.086115</td>\n      <td>0.068998</td>\n      <td>0.075101</td>\n      <td>0.081550</td>\n      <td>0.082987</td>\n      <td>0.075951</td>\n      <td>...</td>\n      <td>0.078393</td>\n      <td>0.053319</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.430208</td>\n      <td>5.758408</td>\n      <td>51.152721</td>\n      <td>60.381077</td>\n      <td>21.515299</td>\n      <td>4.466881</td>\n      <td>13.074950</td>\n      <td>55.018288</td>\n      <td>43.365993</td>\n      <td>16.410397</td>\n      <td>...</td>\n      <td>25.460247</td>\n      <td>5.669981</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.356129</td>\n      <td>2.768868</td>\n      <td>10.043193</td>\n      <td>5.306677</td>\n      <td>2.211567</td>\n      <td>2.200262</td>\n      <td>5.633092</td>\n      <td>11.511503</td>\n      <td>4.667964</td>\n      <td>2.912486</td>\n      <td>...</td>\n      <td>5.367310</td>\n      <td>2.295357</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.119155</td>\n      <td>0.518129</td>\n      <td>1.104150</td>\n      <td>0.707675</td>\n      <td>0.361656</td>\n      <td>0.435153</td>\n      <td>0.531613</td>\n      <td>1.172129</td>\n      <td>1.274063</td>\n      <td>1.586210</td>\n      <td>...</td>\n      <td>1.393059</td>\n      <td>0.565431</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.200908</td>\n      <td>0.502827</td>\n      <td>0.919906</td>\n      <td>0.679136</td>\n      <td>0.617777</td>\n      <td>0.499163</td>\n      <td>0.740346</td>\n      <td>0.879904</td>\n      <td>0.768322</td>\n      <td>0.788436</td>\n      <td>...</td>\n      <td>1.237146</td>\n      <td>0.505317</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 181 columns</p>\n</div>"},"metadata":{}}],"execution_count":157},{"cell_type":"code","source":"val_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:17:42.038624Z","iopub.execute_input":"2025-06-08T12:17:42.039009Z","iopub.status.idle":"2025-06-08T12:17:42.061830Z","shell.execute_reply.started":"2025-06-08T12:17:42.038983Z","shell.execute_reply":"2025-06-08T12:17:42.060914Z"}},"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"          0         1          2         3          4          5         6  \\\n0  0.044180  0.056054   0.064415  0.069324   0.067334   0.067759  0.071800   \n1  1.723533  5.687970   9.228014  7.410962   7.198935  11.340713  7.369151   \n2  2.469047  7.855614  10.789010  9.705440  11.964504  14.177218  9.775521   \n3  2.648386  5.412858   5.202138  6.334105  10.531077   8.599378  4.707143   \n4  0.576799  1.618431   2.621299  1.711736   1.985173   2.103726  1.531987   \n\n           7          8         9  ...        171        172  173  174  175  \\\n0   0.069728   0.069248  0.065749  ...   0.070372   0.061280  0.0  0.0  0.0   \n1  10.589535  10.131034  3.039403  ...  14.573446  10.166873  0.0  0.0  0.0   \n2  12.749818  11.203400  4.147494  ...  12.323687   5.084070  0.0  0.0  0.0   \n3   6.276899   5.755446  8.934631  ...  10.442652   4.127263  0.0  0.0  0.0   \n4   2.888803   3.074646  3.813351  ...   4.061364   3.374841  0.0  0.0  0.0   \n\n   176  177  178  179       Label  \n0  0.0  0.0  0.0  0.0  jackhammer  \n1  0.0  0.0  0.0  0.0  jackhammer  \n2  0.0  0.0  0.0  0.0  jackhammer  \n3  0.0  0.0  0.0  0.0  jackhammer  \n4  0.0  0.0  0.0  0.0  jackhammer  \n\n[5 rows x 181 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>171</th>\n      <th>172</th>\n      <th>173</th>\n      <th>174</th>\n      <th>175</th>\n      <th>176</th>\n      <th>177</th>\n      <th>178</th>\n      <th>179</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.044180</td>\n      <td>0.056054</td>\n      <td>0.064415</td>\n      <td>0.069324</td>\n      <td>0.067334</td>\n      <td>0.067759</td>\n      <td>0.071800</td>\n      <td>0.069728</td>\n      <td>0.069248</td>\n      <td>0.065749</td>\n      <td>...</td>\n      <td>0.070372</td>\n      <td>0.061280</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.723533</td>\n      <td>5.687970</td>\n      <td>9.228014</td>\n      <td>7.410962</td>\n      <td>7.198935</td>\n      <td>11.340713</td>\n      <td>7.369151</td>\n      <td>10.589535</td>\n      <td>10.131034</td>\n      <td>3.039403</td>\n      <td>...</td>\n      <td>14.573446</td>\n      <td>10.166873</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.469047</td>\n      <td>7.855614</td>\n      <td>10.789010</td>\n      <td>9.705440</td>\n      <td>11.964504</td>\n      <td>14.177218</td>\n      <td>9.775521</td>\n      <td>12.749818</td>\n      <td>11.203400</td>\n      <td>4.147494</td>\n      <td>...</td>\n      <td>12.323687</td>\n      <td>5.084070</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.648386</td>\n      <td>5.412858</td>\n      <td>5.202138</td>\n      <td>6.334105</td>\n      <td>10.531077</td>\n      <td>8.599378</td>\n      <td>4.707143</td>\n      <td>6.276899</td>\n      <td>5.755446</td>\n      <td>8.934631</td>\n      <td>...</td>\n      <td>10.442652</td>\n      <td>4.127263</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.576799</td>\n      <td>1.618431</td>\n      <td>2.621299</td>\n      <td>1.711736</td>\n      <td>1.985173</td>\n      <td>2.103726</td>\n      <td>1.531987</td>\n      <td>2.888803</td>\n      <td>3.074646</td>\n      <td>3.813351</td>\n      <td>...</td>\n      <td>4.061364</td>\n      <td>3.374841</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>jackhammer</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 181 columns</p>\n</div>"},"metadata":{}}],"execution_count":158},{"cell_type":"markdown","source":"# Dataset Loader","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nN_WORKERS = torch.cuda.device_count() if torch.cuda.device_count() > 1 else 1\nN_WORKERS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:09.561951Z","iopub.execute_input":"2025-06-08T12:07:09.562339Z","iopub.status.idle":"2025-06-08T12:07:09.570611Z","shell.execute_reply.started":"2025-06-08T12:07:09.562308Z","shell.execute_reply":"2025-06-08T12:07:09.569509Z"}},"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":130},{"cell_type":"code","source":"label_map = {\n    'air_conditioner': 0,\n    'car_horn': 1,\n    'children_playing': 2,\n    'dog_bark': 3,\n    'drilling': 4,\n    'engine_idling': 5,\n    'gun_shot': 6,\n    'jackhammer': 7,\n    'siren': 8,\n    'street_music': 9\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:09.783808Z","iopub.execute_input":"2025-06-08T12:07:09.784153Z","iopub.status.idle":"2025-06-08T12:07:09.789536Z","shell.execute_reply.started":"2025-06-08T12:07:09.784130Z","shell.execute_reply":"2025-06-08T12:07:09.788308Z"}},"outputs":[],"execution_count":131},{"cell_type":"code","source":"class UrbanSound8kDataset(Dataset):\n    \"\"\" Diabetes dataset.\"\"\"\n\n    # Initialize your data, download, etc.\n    def __init__(self, file_path):\n        with open(file_path, 'rb') as f:\n            self.x_data, self.y_data = pickle.load(f)\n        self.len = len(self.x_data)\n        self.y_data = np.array([label_map[label] for label in self.y_data])\n\n    def __getitem__(self, idx):\n        x = self.x_data[idx].astype(np.float32)   # <- fix here\n        y = self.y_data[idx]\n        # print(type(x[0][0]))\n        # print(y)\n        # print(torch.tensor(y, dtype=torch.long))\n        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n\n    def __len__(self):\n        return self.len\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:11.587243Z","iopub.execute_input":"2025-06-08T12:07:11.587662Z","iopub.status.idle":"2025-06-08T12:07:11.596803Z","shell.execute_reply.started":"2025-06-08T12:07:11.587637Z","shell.execute_reply":"2025-06-08T12:07:11.595772Z"}},"outputs":[],"execution_count":132},{"cell_type":"code","source":"train_dataset = UrbanSound8kDataset('/kaggle/input/urbansound8k-feature-extraction/train_data.pkl')\ntrain_loader = DataLoader(dataset=train_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True,\n                          num_workers=N_WORKERS)\nval_dataset = UrbanSound8kDataset('/kaggle/input/urbansound8k-feature-extraction/val_data.pkl')\nval_loader = DataLoader(dataset=val_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True,\n                          num_workers=N_WORKERS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:40:48.955868Z","iopub.execute_input":"2025-06-08T12:40:48.956766Z","iopub.status.idle":"2025-06-08T12:40:52.013514Z","shell.execute_reply.started":"2025-06-08T12:40:48.956733Z","shell.execute_reply":"2025-06-08T12:40:52.012386Z"}},"outputs":[],"execution_count":165},{"cell_type":"code","source":"print(len(train_dataset), len(train_dataset[0]), len(train_dataset[0][0]), len(train_dataset[0][0][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:40:52.015004Z","iopub.execute_input":"2025-06-08T12:40:52.015308Z","iopub.status.idle":"2025-06-08T12:40:52.022651Z","shell.execute_reply.started":"2025-06-08T12:40:52.015286Z","shell.execute_reply":"2025-06-08T12:40:52.021631Z"}},"outputs":[{"name":"stdout","text":"21740 2 54 180\n","output_type":"stream"}],"execution_count":166},{"cell_type":"code","source":"print(len(train_dataset), len(train_dataset[1]), train_dataset[1][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:40:52.023909Z","iopub.execute_input":"2025-06-08T12:40:52.024368Z","iopub.status.idle":"2025-06-08T12:40:52.042509Z","shell.execute_reply.started":"2025-06-08T12:40:52.024329Z","shell.execute_reply":"2025-06-08T12:40:52.041665Z"}},"outputs":[{"name":"stdout","text":"21740 2 tensor(7)\n","output_type":"stream"}],"execution_count":167},{"cell_type":"code","source":"print(len(val_dataset), len(val_dataset[0]), len(val_dataset[0][0]), len(val_dataset[0][0][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:40:52.044240Z","iopub.execute_input":"2025-06-08T12:40:52.044554Z","iopub.status.idle":"2025-06-08T12:40:52.064901Z","shell.execute_reply.started":"2025-06-08T12:40:52.044530Z","shell.execute_reply":"2025-06-08T12:40:52.064027Z"}},"outputs":[{"name":"stdout","text":"6576 2 54 180\n","output_type":"stream"}],"execution_count":168},{"cell_type":"code","source":"print(len(val_dataset), len(val_dataset[1]), val_dataset[1][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:40:52.066130Z","iopub.execute_input":"2025-06-08T12:40:52.066399Z","iopub.status.idle":"2025-06-08T12:40:52.083230Z","shell.execute_reply.started":"2025-06-08T12:40:52.066379Z","shell.execute_reply":"2025-06-08T12:40:52.082332Z"}},"outputs":[{"name":"stdout","text":"6576 2 tensor(7)\n","output_type":"stream"}],"execution_count":169},{"cell_type":"markdown","source":"# RNN Model","metadata":{}},{"cell_type":"code","source":"class RNNClassifier(nn.Module):\n    # Our model\n\n    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n        super(RNNClassifier, self).__init__()\n        self.hidden_size = hidden_size\n        self.n_layers = n_layers\n        self.n_directions = int(bidirectional) + 1\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.rnn = nn.RNN(input_size, hidden_size, n_layers,\n                          bidirectional=bidirectional, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, signal):\n        # Note: we run this all at once (over the whole input sequence)\n        # input shape: B x S (input size)\n        # transpose to make S(sequence) x B (batch)\n        # input = input.t()\n        batch_size = signal.size(0)\n        signal = signal.permute(0, 2, 1)\n\n        # Make a hidden\n        hidden = self._init_hidden(batch_size)\n        # print(\"hidden shape: \", hidden.shape)\n        # print(\"signal shape: \", signal.shape)\n        # # Embedding S x B -> S x B x I (embedding size)\n        # embedded = self.embedding(input)\n\n        # # Pack them up nicely\n        # gru_input = pack_padded_sequence(\n        #     embedded, seq_lengths.data.cpu().numpy())\n\n        # To compact weights again call flatten_parameters().\n        # self.gru.flatten_parameters()\n        output, hidden = self.rnn(signal, hidden)\n    \n        # print(\"output shape: \", output.shape)\n        # Use the last layer output as FC's input\n        # No need to unpack, since we are going to use hidden\n        fc_output = self.fc(hidden[-1])\n        # print(\"fc_output shape: \", fc_output.shape)\n        \n        return fc_output\n\n    def _init_hidden(self, batch_size):\n        hidden = torch.zeros(self.n_layers * self.n_directions,\n                             batch_size, self.hidden_size)\n        return create_variable(hidden)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:17.398115Z","iopub.execute_input":"2025-06-08T12:07:17.398463Z","iopub.status.idle":"2025-06-08T12:07:17.414266Z","shell.execute_reply.started":"2025-06-08T12:07:17.398433Z","shell.execute_reply":"2025-06-08T12:07:17.413105Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"# Train cycle\ndef train():\n    total_loss = 0\n\n    for i, (signal, label) in enumerate(train_loader, 1):\n        output = classifier(signal)\n        # print(\"signal size: \", signal.shape)\n        # print(\"label size: \", label.shape)\n        # print(\"label: \", label)\n        loss = criterion(output, label)\n        total_loss += loss.item()\n\n        classifier.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i % 100 == 0:\n            print('[{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.2f}'.format(\n                time_since(start), epoch,  i *\n                len(signal), len(train_loader.dataset),\n                100. * i * len(signal) / len(train_loader.dataset),\n                total_loss / i * len(signal)))\n\n    return total_loss\n\n\n# Testing cycle\ndef test(name=None):\n    \n    print(\"evaluating trained model ...\")\n    correct = 0\n    train_data_size = len(val_loader.dataset)\n\n    for signal, label in val_loader:\n        output = classifier(signal)\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n\n    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        correct, train_data_size, 100. * correct / train_data_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:14.465364Z","iopub.execute_input":"2025-06-08T12:11:14.465722Z","iopub.status.idle":"2025-06-08T12:11:14.475373Z","shell.execute_reply.started":"2025-06-08T12:11:14.465691Z","shell.execute_reply":"2025-06-08T12:11:14.473983Z"}},"outputs":[],"execution_count":147},{"cell_type":"markdown","source":"# Some utility functions","metadata":{}},{"cell_type":"code","source":"def create_variable(tensor):\n    # Do cuda() before wrapping with variable\n    if torch.cuda.is_available():\n        return Variable(tensor.cuda())\n    else:\n        return Variable(tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:22.114132Z","iopub.execute_input":"2025-06-08T12:07:22.114432Z","iopub.status.idle":"2025-06-08T12:07:22.119701Z","shell.execute_reply.started":"2025-06-08T12:07:22.114414Z","shell.execute_reply":"2025-06-08T12:07:22.118547Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"def time_since(since):\n    s = time.time() - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:22.530889Z","iopub.execute_input":"2025-06-08T12:07:22.531241Z","iopub.status.idle":"2025-06-08T12:07:22.536697Z","shell.execute_reply.started":"2025-06-08T12:07:22.531215Z","shell.execute_reply":"2025-06-08T12:07:22.535543Z"}},"outputs":[],"execution_count":139},{"cell_type":"markdown","source":"# Model Training & Valuation","metadata":{}},{"cell_type":"code","source":"N_EPOCHS = 100\n\nN_INPUT = 54\nHIDDEN_SIZE = 180\nN_CLASSES = 10\nN_LAYERS = 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:40:45.737644Z","iopub.execute_input":"2025-06-08T12:40:45.738091Z","iopub.status.idle":"2025-06-08T12:40:45.744098Z","shell.execute_reply.started":"2025-06-08T12:40:45.738025Z","shell.execute_reply":"2025-06-08T12:40:45.743119Z"}},"outputs":[],"execution_count":163},{"cell_type":"code","source":"N_EPOCHS = 100\n\nN_INPUT = 54\nHIDDEN_SIZE = 180\nN_CLASSES = 10\nN_LAYERS = 2\n\nclassifier = RNNClassifier(\n    input_size=N_INPUT,\n    hidden_size=HIDDEN_SIZE,\n    output_size=N_CLASSES,\n    n_layers=N_LAYERS,\n    # bidirectional=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:40:57.238148Z","iopub.execute_input":"2025-06-08T12:40:57.238475Z","iopub.status.idle":"2025-06-08T12:40:57.248675Z","shell.execute_reply.started":"2025-06-08T12:40:57.238452Z","shell.execute_reply":"2025-06-08T12:40:57.247442Z"}},"outputs":[],"execution_count":170},{"cell_type":"code","source":"if torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    # dim = 0 [33, xxx] -> [11, ...], [11, ...], [11, ...] on 3 GPUs\n    classifier = nn.DataParallel(classifier)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:41:00.644682Z","iopub.execute_input":"2025-06-08T12:41:00.645026Z","iopub.status.idle":"2025-06-08T12:41:00.651404Z","shell.execute_reply.started":"2025-06-08T12:41:00.645001Z","shell.execute_reply":"2025-06-08T12:41:00.650110Z"}},"outputs":[],"execution_count":171},{"cell_type":"code","source":"if torch.cuda.is_available():\n    classifier.cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:41:02.551207Z","iopub.execute_input":"2025-06-08T12:41:02.551530Z","iopub.status.idle":"2025-06-08T12:41:02.557072Z","shell.execute_reply.started":"2025-06-08T12:41:02.551507Z","shell.execute_reply":"2025-06-08T12:41:02.555940Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\nstart = time.time()\nprint(\"Training for %d epochs...\" % N_EPOCHS)\nfor epoch in range(1, N_EPOCHS + 1):\n    # Train cycle\n    train()\n\n    # Testing\n    test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:41:03.235654Z","iopub.execute_input":"2025-06-08T12:41:03.236025Z","iopub.status.idle":"2025-06-08T13:26:02.918684Z","shell.execute_reply.started":"2025-06-08T12:41:03.235997Z","shell.execute_reply":"2025-06-08T13:26:02.917185Z"}},"outputs":[{"name":"stdout","text":"Training for 100 epochs...\n[1m 56s] Train Epoch: 1 [3200/21740 (15%)]\tLoss: 57.34\n[3m 55s] Train Epoch: 1 [6400/21740 (29%)]\tLoss: 52.60\n[5m 35s] Train Epoch: 1 [9600/21740 (44%)]\tLoss: 49.37\n[7m 26s] Train Epoch: 1 [12800/21740 (59%)]\tLoss: 47.55\n[8m 56s] Train Epoch: 1 [16000/21740 (74%)]\tLoss: 45.79\n[10m 18s] Train Epoch: 1 [19200/21740 (88%)]\tLoss: 44.34\nevaluating trained model ...\n\nTest set: Accuracy: 2863/6576 (44%)\n\n[13m 1s] Train Epoch: 2 [3200/21740 (15%)]\tLoss: 34.19\n[14m 11s] Train Epoch: 2 [6400/21740 (29%)]\tLoss: 33.51\n[15m 18s] Train Epoch: 2 [9600/21740 (44%)]\tLoss: 32.68\n[16m 24s] Train Epoch: 2 [12800/21740 (59%)]\tLoss: 32.39\n[17m 25s] Train Epoch: 2 [16000/21740 (74%)]\tLoss: 32.03\n[18m 30s] Train Epoch: 2 [19200/21740 (88%)]\tLoss: 31.69\nevaluating trained model ...\n\nTest set: Accuracy: 2991/6576 (45%)\n\n[20m 53s] Train Epoch: 3 [3200/21740 (15%)]\tLoss: 27.60\n[21m 56s] Train Epoch: 3 [6400/21740 (29%)]\tLoss: 27.63\n[23m 0s] Train Epoch: 3 [9600/21740 (44%)]\tLoss: 27.09\n[24m 4s] Train Epoch: 3 [12800/21740 (59%)]\tLoss: 27.23\n[25m 9s] Train Epoch: 3 [16000/21740 (74%)]\tLoss: 27.22\n[26m 12s] Train Epoch: 3 [19200/21740 (88%)]\tLoss: 27.27\nevaluating trained model ...\n\nTest set: Accuracy: 2959/6576 (45%)\n\n[28m 18s] Train Epoch: 4 [3200/21740 (15%)]\tLoss: 24.78\n[29m 19s] Train Epoch: 4 [6400/21740 (29%)]\tLoss: 24.30\n[30m 20s] Train Epoch: 4 [9600/21740 (44%)]\tLoss: 24.53\n[31m 16s] Train Epoch: 4 [12800/21740 (59%)]\tLoss: 24.75\n[32m 12s] Train Epoch: 4 [16000/21740 (74%)]\tLoss: 24.86\n[33m 7s] Train Epoch: 4 [19200/21740 (88%)]\tLoss: 24.76\nevaluating trained model ...\n\nTest set: Accuracy: 2841/6576 (43%)\n\n[35m 7s] Train Epoch: 5 [3200/21740 (15%)]\tLoss: 22.89\n[36m 2s] Train Epoch: 5 [6400/21740 (29%)]\tLoss: 24.69\n[37m 0s] Train Epoch: 5 [9600/21740 (44%)]\tLoss: 23.88\n[37m 55s] Train Epoch: 5 [12800/21740 (59%)]\tLoss: 23.57\n[38m 48s] Train Epoch: 5 [16000/21740 (74%)]\tLoss: 23.74\n[39m 44s] Train Epoch: 5 [19200/21740 (88%)]\tLoss: 23.64\nevaluating trained model ...\n\nTest set: Accuracy: 2930/6576 (45%)\n\n[41m 52s] Train Epoch: 6 [3200/21740 (15%)]\tLoss: 24.36\n[42m 54s] Train Epoch: 6 [6400/21740 (29%)]\tLoss: 24.31\n[43m 57s] Train Epoch: 6 [9600/21740 (44%)]\tLoss: 26.18\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/705636435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Train cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/607788500.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":173},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}