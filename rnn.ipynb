{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12092109,"sourceType":"datasetVersion","datasetId":7612161}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pickle\n\nimport time\nimport math\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\n\n# from name_dataset import NameDataset\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:53:24.933117Z","iopub.execute_input":"2025-06-08T10:53:24.933390Z","iopub.status.idle":"2025-06-08T10:53:26.989713Z","shell.execute_reply.started":"2025-06-08T10:53:24.933370Z","shell.execute_reply":"2025-06-08T10:53:26.988859Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Dataset Loader","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nN_WORKERS = torch.cuda.device_count() if torch.cuda.device_count() > 1 else 1\nN_WORKERS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:09.561951Z","iopub.execute_input":"2025-06-08T12:07:09.562339Z","iopub.status.idle":"2025-06-08T12:07:09.570611Z","shell.execute_reply.started":"2025-06-08T12:07:09.562308Z","shell.execute_reply":"2025-06-08T12:07:09.569509Z"}},"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":130},{"cell_type":"code","source":"label_map = {\n    'air_conditioner': 0,\n    'car_horn': 1,\n    'children_playing': 2,\n    'dog_bark': 3,\n    'drilling': 4,\n    'engine_idling': 5,\n    'gun_shot': 6,\n    'jackhammer': 7,\n    'siren': 8,\n    'street_music': 9\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:09.783808Z","iopub.execute_input":"2025-06-08T12:07:09.784153Z","iopub.status.idle":"2025-06-08T12:07:09.789536Z","shell.execute_reply.started":"2025-06-08T12:07:09.784130Z","shell.execute_reply":"2025-06-08T12:07:09.788308Z"}},"outputs":[],"execution_count":131},{"cell_type":"code","source":"class UrbanSound8kDataset(Dataset):\n    \"\"\" Diabetes dataset.\"\"\"\n\n    # Initialize your data, download, etc.\n    def __init__(self, file_path):\n        with open(file_path, 'rb') as f:\n            self.x_data, self.y_data = pickle.load(f)\n        self.len = len(self.x_data)\n        self.y_data = np.array([label_map[label] for label in self.y_data])\n\n    def __getitem__(self, idx):\n        x = self.x_data[idx].astype(np.float32)   # <- fix here\n        y = self.y_data[idx]\n        # print(type(x[0][0]))\n        # print(y)\n        # print(torch.tensor(y, dtype=torch.long))\n        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n\n    def __len__(self):\n        return self.len\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:11.587243Z","iopub.execute_input":"2025-06-08T12:07:11.587662Z","iopub.status.idle":"2025-06-08T12:07:11.596803Z","shell.execute_reply.started":"2025-06-08T12:07:11.587637Z","shell.execute_reply":"2025-06-08T12:07:11.595772Z"}},"outputs":[],"execution_count":132},{"cell_type":"code","source":"train_dataset = UrbanSound8kDataset('/kaggle/input/urbansound8k-feature-extraction/train_data.pkl')\ntrain_loader = DataLoader(dataset=train_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True,\n                          num_workers=N_WORKERS)\nval_dataset = UrbanSound8kDataset('/kaggle/input/urbansound8k-feature-extraction/val_data.pkl')\nval_loader = DataLoader(dataset=val_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True,\n                          num_workers=N_WORKERS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:11.813133Z","iopub.execute_input":"2025-06-08T12:07:11.814014Z","iopub.status.idle":"2025-06-08T12:07:17.367610Z","shell.execute_reply.started":"2025-06-08T12:07:11.813985Z","shell.execute_reply":"2025-06-08T12:07:17.366498Z"}},"outputs":[],"execution_count":133},{"cell_type":"code","source":"print(len(train_dataset), len(train_dataset[0]), len(train_dataset[0][0]), len(train_dataset[0][0][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:17.369301Z","iopub.execute_input":"2025-06-08T12:07:17.369684Z","iopub.status.idle":"2025-06-08T12:07:17.376532Z","shell.execute_reply.started":"2025-06-08T12:07:17.369651Z","shell.execute_reply":"2025-06-08T12:07:17.375562Z"}},"outputs":[{"name":"stdout","text":"21740 2 54 180\n","output_type":"stream"}],"execution_count":134},{"cell_type":"code","source":"print(len(train_dataset), len(train_dataset[1]), train_dataset[1][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:17.377489Z","iopub.execute_input":"2025-06-08T12:07:17.377731Z","iopub.status.idle":"2025-06-08T12:07:17.396317Z","shell.execute_reply.started":"2025-06-08T12:07:17.377712Z","shell.execute_reply":"2025-06-08T12:07:17.395297Z"}},"outputs":[{"name":"stdout","text":"21740 2 tensor(7)\n","output_type":"stream"}],"execution_count":135},{"cell_type":"markdown","source":"# RNN Model","metadata":{}},{"cell_type":"code","source":"class RNNClassifier(nn.Module):\n    # Our model\n\n    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n        super(RNNClassifier, self).__init__()\n        self.hidden_size = hidden_size\n        self.n_layers = n_layers\n        self.n_directions = int(bidirectional) + 1\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.rnn = nn.RNN(input_size, hidden_size, n_layers,\n                          bidirectional=bidirectional, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, signal):\n        # Note: we run this all at once (over the whole input sequence)\n        # input shape: B x S (input size)\n        # transpose to make S(sequence) x B (batch)\n        # input = input.t()\n        batch_size = signal.size(0)\n        signal = signal.permute(0, 2, 1)\n\n        # Make a hidden\n        hidden = self._init_hidden(batch_size)\n        # print(\"hidden shape: \", hidden.shape)\n        # print(\"signal shape: \", signal.shape)\n        # # Embedding S x B -> S x B x I (embedding size)\n        # embedded = self.embedding(input)\n\n        # # Pack them up nicely\n        # gru_input = pack_padded_sequence(\n        #     embedded, seq_lengths.data.cpu().numpy())\n\n        # To compact weights again call flatten_parameters().\n        # self.gru.flatten_parameters()\n        output, hidden = self.rnn(signal, hidden)\n    \n        # print(\"output shape: \", output.shape)\n        # Use the last layer output as FC's input\n        # No need to unpack, since we are going to use hidden\n        fc_output = self.fc(hidden[-1])\n        # print(\"fc_output shape: \", fc_output.shape)\n        \n        return fc_output\n\n    def _init_hidden(self, batch_size):\n        hidden = torch.zeros(self.n_layers * self.n_directions,\n                             batch_size, self.hidden_size)\n        return create_variable(hidden)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:17.398115Z","iopub.execute_input":"2025-06-08T12:07:17.398463Z","iopub.status.idle":"2025-06-08T12:07:17.414266Z","shell.execute_reply.started":"2025-06-08T12:07:17.398433Z","shell.execute_reply":"2025-06-08T12:07:17.413105Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"# Train cycle\ndef train():\n    total_loss = 0\n\n    for i, (signal, label) in enumerate(train_loader, 1):\n        output = classifier(signal)\n        # print(\"signal size: \", signal.shape)\n        # print(\"label size: \", label.shape)\n        # print(\"label: \", label)\n        loss = criterion(output, label)\n        total_loss += loss.item()\n\n        classifier.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i % 100 == 0:\n            print('[{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.2f}'.format(\n                time_since(start), epoch,  i *\n                len(signal), len(train_loader.dataset),\n                100. * i * len(signal) / len(train_loader.dataset),\n                total_loss / i * len(signal)))\n\n    return total_loss\n\n\n# Testing cycle\ndef test(name=None):\n    \n    print(\"evaluating trained model ...\")\n    correct = 0\n    train_data_size = len(val_loader.dataset)\n\n    for signal, label in val_loader:\n        output = classifier(signal)\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n\n    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        correct, train_data_size, 100. * correct / train_data_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:14.465364Z","iopub.execute_input":"2025-06-08T12:11:14.465722Z","iopub.status.idle":"2025-06-08T12:11:14.475373Z","shell.execute_reply.started":"2025-06-08T12:11:14.465691Z","shell.execute_reply":"2025-06-08T12:11:14.473983Z"}},"outputs":[],"execution_count":147},{"cell_type":"markdown","source":"# Some utility functions","metadata":{}},{"cell_type":"code","source":"def create_variable(tensor):\n    # Do cuda() before wrapping with variable\n    if torch.cuda.is_available():\n        return Variable(tensor.cuda())\n    else:\n        return Variable(tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:22.114132Z","iopub.execute_input":"2025-06-08T12:07:22.114432Z","iopub.status.idle":"2025-06-08T12:07:22.119701Z","shell.execute_reply.started":"2025-06-08T12:07:22.114414Z","shell.execute_reply":"2025-06-08T12:07:22.118547Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"def time_since(since):\n    s = time.time() - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:22.530889Z","iopub.execute_input":"2025-06-08T12:07:22.531241Z","iopub.status.idle":"2025-06-08T12:07:22.536697Z","shell.execute_reply.started":"2025-06-08T12:07:22.531215Z","shell.execute_reply":"2025-06-08T12:07:22.535543Z"}},"outputs":[],"execution_count":139},{"cell_type":"markdown","source":"# Model Training & Valuation","metadata":{}},{"cell_type":"code","source":"N_EPOCHS = 100\n\nN_INPUT = 54\nHIDDEN_SIZE = 180\nN_CLASSES = 10\nN_LAYERS = 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:25.636124Z","iopub.execute_input":"2025-06-08T12:07:25.636444Z","iopub.status.idle":"2025-06-08T12:07:25.641220Z","shell.execute_reply.started":"2025-06-08T12:07:25.636421Z","shell.execute_reply":"2025-06-08T12:07:25.640124Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"N_EPOCHS = 100\n\nN_INPUT = 54\nHIDDEN_SIZE = 180\nN_CLASSES = 10\nN_LAYERS = 1\n\nclassifier = RNNClassifier(\n    input_size=N_INPUT,\n    hidden_size=HIDDEN_SIZE,\n    output_size=N_CLASSES,\n    n_layers=N_LAYERS,\n    bidirectional=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:25.939247Z","iopub.execute_input":"2025-06-08T12:07:25.939534Z","iopub.status.idle":"2025-06-08T12:07:25.947355Z","shell.execute_reply.started":"2025-06-08T12:07:25.939515Z","shell.execute_reply":"2025-06-08T12:07:25.946210Z"}},"outputs":[],"execution_count":141},{"cell_type":"code","source":"if torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    # dim = 0 [33, xxx] -> [11, ...], [11, ...], [11, ...] on 3 GPUs\n    classifier = nn.DataParallel(classifier)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:26.467746Z","iopub.execute_input":"2025-06-08T12:07:26.468117Z","iopub.status.idle":"2025-06-08T12:07:26.473833Z","shell.execute_reply.started":"2025-06-08T12:07:26.468090Z","shell.execute_reply":"2025-06-08T12:07:26.472830Z"}},"outputs":[],"execution_count":142},{"cell_type":"code","source":"if torch.cuda.is_available():\n    classifier.cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:27.970507Z","iopub.execute_input":"2025-06-08T12:07:27.970832Z","iopub.status.idle":"2025-06-08T12:07:27.975896Z","shell.execute_reply.started":"2025-06-08T12:07:27.970809Z","shell.execute_reply":"2025-06-08T12:07:27.974813Z"}},"outputs":[],"execution_count":143},{"cell_type":"code","source":"optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\nstart = time.time()\nprint(\"Training for %d epochs...\" % N_EPOCHS)\nfor epoch in range(1, N_EPOCHS + 1):\n    # Train cycle\n    train()\n\n    # Testing\n    test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:07:30.237522Z","iopub.execute_input":"2025-06-08T12:07:30.237854Z","iopub.status.idle":"2025-06-08T12:09:09.478477Z","shell.execute_reply.started":"2025-06-08T12:07:30.237828Z","shell.execute_reply":"2025-06-08T12:09:09.477113Z"}},"outputs":[{"name":"stdout","text":"Training for 100 epochs...\n[0m 14s] Train Epoch: 1 [3200/21740 (15%)]\tLoss: 65.37\n[0m 28s] Train Epoch: 1 [6400/21740 (29%)]\tLoss: 60.45\n[0m 42s] Train Epoch: 1 [9600/21740 (44%)]\tLoss: 57.11\n[0m 57s] Train Epoch: 1 [12800/21740 (59%)]\tLoss: 55.49\n[1m 12s] Train Epoch: 1 [16000/21740 (74%)]\tLoss: 55.44\n[1m 27s] Train Epoch: 1 [19200/21740 (88%)]\tLoss: 55.87\nevaluating trained model ...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/705636435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/4186826176.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'seq_lengths' is not defined"],"ename":"NameError","evalue":"name 'seq_lengths' is not defined","output_type":"error"}],"execution_count":144},{"cell_type":"code","source":"test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:19.897001Z","iopub.execute_input":"2025-06-08T12:11:19.897972Z","iopub.status.idle":"2025-06-08T12:11:24.628469Z","shell.execute_reply.started":"2025-06-08T12:11:19.897944Z","shell.execute_reply":"2025-06-08T12:11:24.627149Z"}},"outputs":[{"name":"stdout","text":"evaluating trained model ...\n\nTest set: Accuracy: 2494/6576 (38%)\n\n","output_type":"stream"}],"execution_count":148},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}